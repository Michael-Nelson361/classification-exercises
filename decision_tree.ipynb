{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9ef22b-d827-4201-9617-73fb8dc0af45",
   "metadata": {},
   "source": [
    "- [ ] Using the titanic data, in your classification-exercises repository, create a notebook, decision_tree.ipynb where you will do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1160ad5-c566-4f78-8b02-b699f3ad1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import acquire as a\n",
    "import prepare as p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d8565-6373-4e9b-9819-bf226855f5d5",
   "metadata": {},
   "source": [
    "1. [ ] What is your baseline prediction? What is your baseline accuracy? *remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39ea1e-ae76-43ce-ad70-26a4419c0835",
   "metadata": {},
   "source": [
    "2. [ ] Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49eb8a9-454b-4867-84a2-66aaf8fb1469",
   "metadata": {},
   "source": [
    "3. [ ] Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2f6bb-9f0e-4344-8de2-ad5b7bdd7d54",
   "metadata": {},
   "source": [
    "4. [ ] Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2601b-4171-44e4-b480-b96ea1e99677",
   "metadata": {},
   "source": [
    "5. [ ] Run through steps 2-4 using a different `max_depth` value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85845f6c-2dc1-40a2-836e-7f45647e78c9",
   "metadata": {},
   "source": [
    "6. [ ] Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa35815-8edc-4631-b3d6-f5df09528019",
   "metadata": {},
   "source": [
    "7. [ ] Which model performs best on your out-of-sample data, the `validate` set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478f794-503a-47b6-ae75-b76667836cf8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. [ ] Work through these same exercises using the Telco dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e853bd6-8e2b-4305-a421-755aad4c6d2d",
   "metadata": {},
   "source": [
    "2. [ ] Experiment with this model on other datasets with a higher number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e14553-03fe-4c38-beb7-60a8ff3a45a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

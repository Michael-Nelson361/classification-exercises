{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84938b62-44fc-433a-b89b-a6585d798118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import acquire\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import functions\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6808ad-d42d-4d62-9530-35f85852eeea",
   "metadata": {},
   "source": [
    "### Using the Iris Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45d1c0-0220-4057-bac8-b10681d011ba",
   "metadata": {},
   "source": [
    "1. Use the function defined in `acquire.py` to load the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5be9e6-b012-4efe-b0b6-65afd0494c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from file...\n"
     ]
    }
   ],
   "source": [
    "iris = acquire.get_iris_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73a41e-ee0b-47d9-b1d9-d968fe4ee4a5",
   "metadata": {},
   "source": [
    "2. Clean up the column names - replace the period with an underscore and lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b916b-5daa-4faa-ac27-d1c404b24461",
   "metadata": {},
   "source": [
    "3. Drop the `species_id` and `measurement_id` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e24ba08-770c-45e2-813c-349f36799b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris = iris.drop(columns=['species_id','measurement_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136dc10-89f7-480c-a9f4-8130c984fc39",
   "metadata": {},
   "source": [
    "4. Rename the `species_name` column to just `species`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20f131d1-4c99-4291-9a22-69e4366dc3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris = iris.rename(columns={'species_name':'species'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f5af86-a1af-4be3-a838-dd36855f4d55",
   "metadata": {},
   "source": [
    "5. Create a function named `prep_iris` that accepts the untransformed iris data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e667599c-5a28-4ec7-b741-87eed335fbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_iris(iris):\n",
    "    \"\"\"\n",
    "    Cleans iris data. Takes a raw dataframe, drops species and measurement IDs, then renames species column. Returns cleaned dataframe.\n",
    "    \"\"\"\n",
    "    iris = iris.drop(columns=['species_id','measurement_id'])\n",
    "    iris = iris.rename(columns={'species_name':'species'})\n",
    "    \n",
    "    return iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a037ea9-c8b1-4d8b-8731-70964107ab44",
   "metadata": {},
   "source": [
    "### Using the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702821a-523e-40b3-be77-c86e915994e1",
   "metadata": {},
   "source": [
    "1. Use the function defined in `acquire.py` to load the Titanic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443fd3c-9e93-42cc-9dee-6cd82f4969f0",
   "metadata": {},
   "source": [
    "2. Drop any unnecessary, unhelpful, or duplicated columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fac897-4d00-4e22-ab51-02743ee0078b",
   "metadata": {},
   "source": [
    "3. Create a function named `prep_titanic` that accepts the raw titanic data, and returns the data with the transformations above applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23122b-c2fa-4c6e-ab28-9b7ab2de9eb9",
   "metadata": {},
   "source": [
    "### Using the Telco dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b026fd70-c321-4888-a3a4-15c4d20884cd",
   "metadata": {},
   "source": [
    "1. Use the function defined in `acquire.py` to load the Telco data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a64253f2-f9c8-487d-86d0-5821d15fec3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from file...\n"
     ]
    }
   ],
   "source": [
    "telco = acquire.get_telco_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c09585-a2cd-42d3-aa1f-fb8018cdc37d",
   "metadata": {},
   "source": [
    "2. Drop any unnecessary, unhelpful, or duplicated columns. This could mean dropping foreign key columns but keeping the corresponding string values, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f57cec6-976b-404e-8a10-dddf39b560b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop extra ID columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105428a-8731-488d-a6d3-cadc19c8765c",
   "metadata": {},
   "source": [
    "3. Handle null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f032b-e414-46d2-81a0-77d6fbf739cf",
   "metadata": {},
   "source": [
    "4. Create a function named `prep_telco` that accepts the raw telco data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18caa359-e765-4553-815c-1d0888861fb2",
   "metadata": {},
   "source": [
    "### Split your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854567bd-950f-4ad9-a2b9-fcd8825f18bb",
   "metadata": {},
   "source": [
    "1. Write a function to split your data into train, test and validate datasets. Add this function to prepare.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b516777-1995-40fd-9b36-37e0cb6fce5f",
   "metadata": {},
   "source": [
    "2. Run the function in your notebook on the Iris dataset, returning 3 datasets, train_iris, validate_iris and test_iris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d1be5-ad2a-49aa-9eef-0bc303c56b48",
   "metadata": {},
   "source": [
    "3. Run the function on the Titanic dataset, returning 3 datasets, train_titanic, validate_titanic and test_titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c3614-86fe-4268-93fe-e3a597a316cc",
   "metadata": {},
   "source": [
    "4. Run the function on the Telco dataset, returning 3 datasets, train_telco, validate_telco and test_telco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccfdc17-9d8a-4130-9c81-08ce042af299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
